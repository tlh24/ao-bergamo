Dec 17 2020

-- Need a GUI, so we can adjust & check the centroid images. 
-- Need consistent numbering on the centroids.  Sometimes it misses some, which changes the meaning - ! 
-- Need to figure out how to convert pixel coordinates into waves or at least physical units. 
-- Some centroids are noisier than others; may have to weight individual centroids. 

Dec 18 2020

Have a gui -- repurposed from the sewing machine project -- seems to work well enough. 
Am thinking that we start with numbering and locations from the reference flat, which can be loaded at the start of the program. 
Need to read a matlab file via libmatio.. 

More importantly, will this wavefront sensor have sufficient precision to stabilize the deformable mirror?  
I guess if there are slow drifts over the whole aperture, probaby not --
to detect slight tip/tilt, on the order of many waves at the edges, you need to average over all the lenslets.  
To increase the sensitivity, we need to increase the focal length.
(Which of course decreases the dynamic range..)
The thorlabs WFS have a focal length of 4.1mm; we are using an array with a fl of 3.17mm.  So, they should be in the same ballpark..

Feb 4 2021

Slowly making progress on this -- looking back on my notes above! 
Need to incoporate active DM control into the C++ program; 
running the loop in matlab is slower. 
In the C++ program we can adjust the DM signal shortly after getting the centroids. 
Trick is to be careful about indexing. 
Flow: 
-- Get centroids. 
-- Index them based on the control matrices
-- Collate into a measurement vector + 1
--- Subtract the mean here; no tip tilt correction.
-- Get the desired zernike modes from matlab (Will need the dZx and dZy matrices)
-- Expand to an identically-sized measurement vector
-- Subtract, matrix multiply..
-- Perform PID control, or just PI control, to update the DM actuators. 

If we hold the zernike matrices and desired modes in the C++ program, 
then we need to do some careful frame synchronization, and can do full modal AO correction without matlab.  (Of course matlab might well be in there for visualization, through memmaped files..)

Variables we need sent to shwfs:
-- mask
-- control matrix Cforward
-- Z, dZx, dZy (this depends on calbrated locations of the centroids .. note we are approximating the derivative as constant here, when it is not & should really be updated as the centroids move.. meh.. given our actual correction tends to be on the order of one pixel, i think this is an OK approximation)

Also, at some point we should obtain a full dataset where the DM is stimulated not just with random noise, but also with Zernike modes.  This data can be used to fit a NN for translating WFS dx dy to actuator control signals, including nonlinearities.  

Feb 19 2021
FOV of the microscope, Olympus 20x objective
1x scan zoom:
X: 408um Y:719um
2x scan zoom: 
X: 202um Y:362um (expected: 204 / 360)
3x scan zoom:
X: 137um Y:240um (expected: 135 / 240)

** fixed in the machine configuration file ** 

Feb 23 2021
Trying out the Zernike modal optimization of image intensity
Using slices from Chris, GFP labeled VTA neurons.  
Looks somewhat ok, though I'm not sure about the improvement: 
Went from 6.74 to 7.32 arbitrary units at 168um from the surface
using 27% of 2065mW at 4x zoom.  (8.6% improvement)
Switching between compensated and uncompensated, I cannot see much of a difference.  
Same test on the surface: 
Image intensity went from 7.03 to 7.79 at 4% f 2051mW, 4 zoom. (10% improvement)
Primary change in observable when switching was lateral shift of a few um. 
Same test 50um deep: 
No change in flurescence intensity.  
Slight correction of order 3 mode 0. (astigmatism)

Feb 25 2021
Changed the logic of zernopt t od two passes through each mode+der: forward and backward. 
If both passes agree that a given coeficient setting is best, then the Zernike command is updated.  
This seems to commonly update astigmatism and a few higher-order modes; 
I suspect what it's doing is semi-optimizing the PSF not to be tight and small, but rather to include out-of-plane fluorescence. 
Testing this code was done on Chris Magnus's GFP labeled VTA neurons
He mad some 300um slices of a fixed brain for this purpose; it's working very well for testing. 
Still, don't get a dramatic improvement in intensity. 
Will need to test on a window?

June 2 2021
The 1um poystyrene beds don't seem to bleach! Or, at least, they bleach very very slowly.  
Power was 4% at 960nm.  
SNR at this power level was very good (though I could have tweaked the GDD a little too.. maxed out is probably the best. )

Green retrobeads are nearly as good -- though my test slide has a much thinner layer than the 1um PS beads. 
They started to bleach (?) after about 10k frames.  Which is plenty for optimization! 

Got some example images from the levelling scope -- will need a custom GUI for aligning the window.  I'm thinking actual = green; reference = magenta.  

August 25 2021

Well, the leveling turned out to be simple -- no custom GUI was required!  You can see the the reflection off the cranial window & center it with just the camera image. 

Need to make some notes on the things I've been doing. 

1 -- changed the genetic optimization to run multiple times during one file recording.  Typically, I've run the optimization for 20k samples, ten times through, with temperature varying from 0.006 to 0.0015.  
This doesn't quite asymptote, but it definitely corrects the wavefront well. 
Based on these recordings, I take the difference in wavefront centroids from the 'best wavefront'
(itself a median of the best 400, as quantified by image brightness)
These deltas are decomposed via SVD.  The resulting V matrix is orthonormal and sorted.  The columns of V are then used as delta basis vectors for adjusting the 'best' or flat wavefront. 
Adjustment is manual, through ten sliders in the shwfs GUI.  Range of the sliders is dictated by 8x the standar deviation of the U*S columns (e.g. what V' is multiplied by..)

In experimentation today, this modification of the desired wavefront only very slightly improved image quality, maybe 2-5%, when looking at Helen / Filip's rats.  
The AO calibration was done with the 1um NH2 terminated polystyrene beads, fluorescein color (& dye, probably).  These don't seem to bleach at all, when stimulated with 1% power at 960nm.  

The idea was to restrict optimization along the same dimensions that the GA moved in order to improve in-vivo brightness and contrast.  
From examination of the V' projected wavefront data, these trajectories are relatively smooth, and don't frequently cross the origin, so it seems plausible that manual line-search in these dimensions would be OK.  

But, not so much ... the calibration is good, image quality is fine, but improvements are not large like desired (>= 2x).  

Still, these jf669 mice are great as they bleach very slowly, and are good for AO experimentation. 

August 27 2021
Green latex retrobeads do not seem to bleach too quickly!  That's good!

Today experimented with SVD of the calibration matrix. 
It looks OK... 
for optimization, suggest we take the components from that, regress them to the associated DM actuator values (through the forward matrix), 
and then search along these directions for online wavefront optimization. 

Also of note: experimented with tweaking the SVD components today while trying to bleach the retrobeads.  The middle setting (e.g. no modification) was consistently the best in terms of brightness for the retrobeads image. 
This adds more evidence to the idea that in order to improve image quality in vivo, 
we need to run the optimization in vivo.  
A corrolary question is: how can we optimize the optimizer? 
Making it operate in a basis set different than the raw actuator values makes sense ... it may also be the case that the function is convex (?) which means that variables can be optimized serially, 
and this will work even if it's not conjugate gradients.  
(could also do simplex optimization?)

Sept 23 2021

SLAP1, Kaspar, Figure 1, much better than my optical schematic (because it's simpler?)
https://www.nature.com/articles/s41592-019-0493-9/figures/1
SLAP records spines at 1016Hz
looks like a good set of references too. 

October 8 2021
The DM most definitely responds within one SHWFS frame.  No problem!
In fact, I think there was a bug in the control code that was slowing things down... 
For speed purposes, might want to reconsider the pipeline / move the optimization to the scanimage computer and simply remote control the DM? 


October 22 2021

Ok, observations: 
1 -- The geneopt is able to recover when a 'hidden' corrupting wavefront / modulation is written to the DM based on in-vivo imaging. 
Just tested this for superficial, will test again at depth. 
2 -- Running the current geneop in-vivo results in an image that is NOT as bright as the result of optimizing in vitro.  relative scaling is 506 / 288, roughly. 
But, I will try again on a smaller bead area. 
Yes, the result holds -- 204 to about 180.  So the optimized result is slightly dimmer, consistent with noise entering the evaluation system. 
(Note that the best flat wavefront was averaged over many trials; it is not just a running average, as you get with the GA. )
3 -- trying 'hidden' recovery with a bright clump of beads at 290um depth.  11% laser power. 
Increased frame averaging (median) to 8 from 6. 
Population size remains 25 (which might need to increase with the larger dimensionality of the search space..). 
It does work .. maybe imperfectly? 
No, it works, it's just rather slow.  Improved the brightness by 4x on a second try. 
4 -- Same thing, 442um deep, 43% laser power, 5x zoom, hidden variable aberration. 
Yes, this definitely worked. 
5 -- Alright, now the real test.  5x zoom, 55% power, 558um deep. 
No hidden variable aberration -- can we fix the sample aberrations? 
(starttemp = 0.37 / endtemp = 0.07, modes 4-86 being optimized). 
It worked slightly!  But then, it bleached.  
6 -- Try again, with hidden variable aberration (only 20 modes this time). 
Yeah, it recovers the image ... only about 50% though. 
7 -- Try this experiment again with another spot, 577um deep. 
stil 65% power. 
Yes, it was able to correct the image, again only about 50% .. 
8 -- Ok, last try!  No hidden aberrations. 
65% power, 577um deep. 
population size increased to 50. 
N increased to 40k. 
same frame averaging of 9 .
No, it failed. Did not work at all .. .humm, maybe too low SNR? 
Seems like it bleached pretty bad.. 
9 -- Same setup, 507um deep, near a vessel (?)
46% power. Very bright image, 2000 scanimage scaling. 
4x zoom.. 
Issue: no water! 
Must chec more frequently! Now I'm not sure if that result was from correcting for the lack of water or correcting for sample aberrations.. 

October 23 2021
1 -- Trying again -- black labeled mouse. 
Certain that there is immersion water this time. 
focusing on a small bead clump, 451um deep, 55% power, 5x zoom, 300 x 512. 
Same also as yesterday. 
No apparent change in brightness. 
2 -- let's see if we can replicate yesterday with loss of immersion water. 
Ok, looks like 600um deep.  right. 
38% laser power. same zoom. 
Yep, the AO can convert an immersion objective to an air objective (imperfectly, but still). 

October 26 2021

Trying out the zonal optimization -- topology-aware recombination. 
1 -- Starting from zero wavefront definitely works!
2 -- Starting from Best_DMcommand also increases the brightness in a small group of beads from ~4.25 to ~6 (arb units). 
Power is 14% of 1871mw, depth is 231um.  
3 -- Power 60% zoom 5 (as above), depth 469um. 
Very little improvement in image quality. 
Actually, It looks like the image got worse vs Best_DMcommand from geneopt! Shoot. 
4 -- Again power 60% zoom 5, depth 397um. did get an increase in brightness! 
173 to 245, thats 41% 
This was a well-labeled spot, though. 
5 -- 50% power, depth 346um, zoom still 5. increase from 5-6 (~20%).  not bad I guess.  Sure wish there was a faster optimization algorithm! 
Also need to start saving the data logs from this! 

I generally think that the modal optimization is much faster for low-order aberrations (e.g. when the immersion water disappears), whereas the zonal per-actuator optimization works better in practice in vivo. 

November 1 2021

Black-marked mouse. 
1 -- Using geneopt, 5x zoom, 44% power, 274um deep. 
No clear improvement of brightness -- but there is an improvement in resolution? 
Had to change the variance on the geneopt from 0.07 and 0.015 to 0.04 and 0.01. 
Saved the wavefront image. 
2 -- 49% power, 293um deep, 
3 -- 65% power, 470um deep, didn't work, too dim. 
4 -- 278um deep, 50% power, no appreciable increase in brightness. Wavefront saved. 


November 13 2021

Ok, November 5th, otally re-aligned the microscope, improved the quality of the WF image (536 centroids consistently viewable), and re-rand geneopt.  
The result is in rundata/DMoptimization_960nm_20211105.mat. 
It's a complete run -- the objective didn't run out of water. 
But it looks the same as other runs... 

Fast-forward to the present (13th), I've replacd the 400mm / 300mm custom tube lens (efl 171mm) with a 400 / 400 lens (efl 200mm).  This should make the DM 'pretty close' to conjugate to the objective pupil plane / 'back focal plane' as Olympis  calls it.  
Of course, then the problem is that 
1 -- The magnification is different
2 -- The size of the pupil plane is correspondingly larger.  (This is because the system was designed for the olympus objective, entrance pupil of ~ 18mm)
3 -- The system is no longer in 4f configuration, because the tube lens is too close to the DM relay TL200-2p2. 
4 -- The wavefront sensor is off, because it's conjugate plane is in the wrong position as well.  Practically speaking, the wavefront isn't even close to flat, so the flat-calibrated centroids don't work well. 
5 -- The window-levelling optics need to be changed as well. 

Because of these differences, and to hopefully get the objective pupil better conjugated to the DM, I switched over to the Nikon 16x 0.8NA from the Olympus 20x 1.0NA.  The Nikon has a BFP 37.4mm from the objective shoulder, whereas the Olympus is 48.1mm from the shoulder. 

I was hoping that this would change things, but the results of the geneopt run (which was incomplete -- objective ran out of water after 5 replicates) seems very similar to runs with the Olympus objective. I am pretty sure, at this point, that the conjugate plane moved, judging from the image when the scanners are on vs off. 
But I really should check.. 
Yes, the scanner is conjugate to the DM, which is conjjugate to a plane ~ 30mm below the PMT arm (really should be 37 - 48mm below!  Yet, this is beter than what it was.. )

Of note: observed the same field-dependent modulattion of brightness by the DM during optimization as before; this effect does not seem to be abrogated by a better alignment of the DM to the objective pupipl plane. 
The AO does seem to get more light out, however.. 
See file doc/20211113 - 16x conjugated vs 20x less conjugated.png

Question is: will it work better in mice?? 
Answer: yes!  it definitely seems to be working better - 
Got a 68% improvement in image brightness compared to system correction. 
This is one sample, at 450um deeo (see data file for 20211113), 
but still it's promising.  

(Of note: I think the optimization got the wavefront correction relatively early (??) though save_sumstd just shows bleaching & the laser power adjustment.) 

I really think I need to go back and re-engineer the whole system for a very accurate conjugation to the pupil plane of the objectives. 
Then, maybe, everything will work. 
